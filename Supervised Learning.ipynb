{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64176343-db75-4d1c-b5fc-d7c7bfa521c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install pandas\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e7d1e-76cb-4bd9-b0ac-b354f8f0f50c",
   "metadata": {},
   "source": [
    "# Supervised Learning Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd03d9-68fd-4fa9-b7cb-a1b2a5aaa67e",
   "metadata": {},
   "source": [
    "1. [Introduction](#introduction)\n",
    "2. [Data Setup](#data-setup)\n",
    "3. [Principal Component Analysis (PCA) Review](#principal-component-analysis-pca-review)\n",
    "    - [Significant Features](#significant-features-identification)\n",
    "4. [Supervised Learning Model Implementation](#supervised-learning-model-implementation)\n",
    "    - [Data Splitting](#data-splitting)\n",
    "    - [Lasso Regression](#lasso-regression)\n",
    "        - [Model Training](#model-training)\n",
    "        - [Model Evaluation](#model-evaluation)\n",
    "    - [Decision Tree](#decision-tree)\n",
    "        - [Model Training](#model-training-1)\n",
    "        - [Model Evaluation](#model-evaluation-1)\n",
    "5. [Comparison of Model Results](#comparison-of-model-results)\n",
    "    - [R squared analysis](#r-squared-analysis)\n",
    "    - [MSE analysis](#mse-analysis)\n",
    "6. [Policy Recommendation](#policy-recommendation-development)\n",
    "    - [Interpretation of Findings](#interpretation-of-findings)\n",
    "    - [Our Policy Recommendations](#formulating-policy-decisions)\n",
    "7. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0d99b-fb21-4029-854c-cc0c3ca33021",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Now that we have performed PCA and clustering to determine key features in the dataset, we would like to support these findings with supervised learning. Our goal in this section is to train easily interpretable supervised learning models to predict digital equity statistics in areas of Michigan. We aim to provide insight into which factors are the most significant in determining digital equity. The relative importance of each feature can be gleaned by the weight given to them during the training of these supervised learning models. With these key features in mind, we will recommend policy decisions that could use this insight to better allocate public funds. Since we are using both categorical and quantitative variables to predict our quantitative equity metric, we plan to compare the efficacy of a lasso regression approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba544d5-4902-4018-b7d2-df2df6d580db",
   "metadata": {},
   "source": [
    "## Data setup\n",
    "Access the upload + download speed results etc. from /results, save as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd1cbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bslcount', 'usufcount', 'percent_usuf', 'avg_d_mbps', 'avg_u_mbps',\n",
       "       'avg_lat_ms', 'cluster_labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = pd.read_csv('../../DATA/results/total.csv')\n",
    "total_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "total_df.set_index('TWNRNGSEC', inplace=True)\n",
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d9ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = total_df.drop(['cluster_labels'], axis=1)\n",
    "y = total_df['cluster_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7c9a0-46bf-4840-9b93-486b3fa1b639",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA) Review\n",
    "Write out which groups our PCA highlighted, and which features emerged as the most significant. We will see if our supervised learning yields the same results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd6ad6-29d2-4215-9fdc-df6f1c39e0f8",
   "metadata": {},
   "source": [
    "### Significant features\n",
    "\n",
    "* bslcount\n",
    "* usufcount\t\n",
    "* percent_usuf\n",
    "* avg_d_mbps\n",
    "* avg_u_mbps\n",
    "* avg_lat_ms\n",
    "* cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373e91a-b159-4bac-b379-1ca541715bd0",
   "metadata": {},
   "source": [
    "## Supervised Learning Model Implementation\n",
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70e3fe5-b287-4bde-b8c5-eb00bf33e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9baae-1a2c-4688-aeb5-149d51c8230a",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc7845d-acd2-4ee4-8748-0679ead328ed",
   "metadata": {},
   "source": [
    "### Lasso training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc61bba3-ca83-4364-a6c7-8db62c742d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train Lasso regression model\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "# Train the model using the training sets\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "lasso_y_pred = lasso.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b4c41-23cd-49e8-83a5-17db98c02cc1",
   "metadata": {},
   "source": [
    "### Lasso evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4cd72b9-d513-443e-bddb-9d8647552bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Coefficients: \n",
      " [ 0.00044387 -0.00017024 -0.          0.00542804  0.0249065   0.00297853]\n",
      "Lasso Mean Squared Error (MSE): 0.135\n",
      "Lasso Root Mean Squared Error (RMSE): 0.367\n",
      "Lasso Mean Absolute Error (MAE): 0.294\n",
      "Lasso R² Score: 0.676\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# lasso_mse = mean_squared_error(y_test, lasso_y_pred)\n",
    "# lasso_rmse = mean_squared_error(y_test, lasso_y_pred, squared=False)\n",
    "\n",
    "print('Lasso Coefficients: \\n', lasso.coef_)\n",
    "\n",
    "# Mean Squared Error\n",
    "lasso_mse = round(metrics.mean_squared_error(y_test, lasso_y_pred),3)\n",
    "print(f\"Lasso Mean Squared Error (MSE): {lasso_mse}\")\n",
    "\n",
    "# Root Mean Squared Error\n",
    "lasso_rmse = round(np.sqrt(lasso_mse),3)\n",
    "print(f\"Lasso Root Mean Squared Error (RMSE): {lasso_rmse}\")\n",
    "\n",
    "# Mean Absolute Error\n",
    "lasso_mae = round(metrics.mean_absolute_error(y_test, lasso_y_pred),3)\n",
    "print(f\"Lasso Mean Absolute Error (MAE): {lasso_mae}\")\n",
    "\n",
    "# R² Score\n",
    "lasso_r2 = round(metrics.r2_score(y_test, lasso_y_pred),3)\n",
    "print(f\"Lasso R² Score: {lasso_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e209a0c",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "### Linear Regression Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b0872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create linear regression object\n",
    "linear_regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "linear_regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "linear_regr_y_pred = linear_regr.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa00517",
   "metadata": {},
   "source": [
    "### Linear Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72a293a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 0.00045089 -0.00023275 -0.02205739  0.00519972  0.02892578  0.00299575]\n",
      "Linear Regression Mean Squared Error (MSE): 0.134\n",
      "Linear Regression Root Mean Squared Error (RMSE): 0.366\n",
      "Linear Regression Mean Absolute Error (MAE): 0.292\n",
      "Linear Regression R² Score: 0.678\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: \\n', linear_regr.coef_)\n",
    "\n",
    "# Mean Squared Error\n",
    "linear_regr_mse = round(metrics.mean_squared_error(y_test, linear_regr_y_pred),3)\n",
    "print(f\"Linear Regression Mean Squared Error (MSE): {linear_regr_mse}\")\n",
    "\n",
    "# Root Mean Squared Error\n",
    "linear_regr_rmse = round(np.sqrt(linear_regr_mse),3)\n",
    "print(f\"Linear Regression Root Mean Squared Error (RMSE): {linear_regr_rmse}\")\n",
    "\n",
    "# Mean Absolute Error\n",
    "linear_regr_mae = round(metrics.mean_absolute_error(y_test, linear_regr_y_pred),3)\n",
    "print(f\"Linear Regression Mean Absolute Error (MAE): {linear_regr_mae}\")\n",
    "\n",
    "# R² Score\n",
    "linear_regr_r2 = round(metrics.r2_score(y_test, linear_regr_y_pred),3)\n",
    "print(f\"Linear Regression R² Score: {linear_regr_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616671c-a03d-43ca-b6a7-f096404573b9",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24809b7c-e9fc-43f3-bfac-85995f938ba1",
   "metadata": {},
   "source": [
    "### Tree training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14fc7422-672b-4d57-8a94-e9d109810e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "tree_model_y_pred = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da139f3b-42ed-4609-96ea-556a065782ce",
   "metadata": {},
   "source": [
    "### Tree evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9421ce7-5844-4635-ae1e-643f4b6f56f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- avg_lat_ms <= 355.00\n",
      "|   |--- avg_u_mbps <= 7.44\n",
      "|   |   |--- avg_d_mbps <= 74.82\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- avg_d_mbps >  74.82\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |--- avg_u_mbps >  7.44\n",
      "|   |   |--- avg_d_mbps <= 54.40\n",
      "|   |   |   |--- avg_u_mbps <= 12.52\n",
      "|   |   |   |   |--- avg_lat_ms <= 32.20\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- avg_lat_ms >  32.20\n",
      "|   |   |   |   |   |--- avg_u_mbps <= 9.84\n",
      "|   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |   |--- avg_u_mbps >  9.84\n",
      "|   |   |   |   |   |   |--- bslcount <= 22.50\n",
      "|   |   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |   |   |--- bslcount >  22.50\n",
      "|   |   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- avg_u_mbps >  12.52\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- avg_d_mbps >  54.40\n",
      "|   |   |   |--- avg_lat_ms <= 308.17\n",
      "|   |   |   |   |--- avg_u_mbps <= 8.07\n",
      "|   |   |   |   |   |--- avg_u_mbps <= 7.96\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- avg_u_mbps >  7.96\n",
      "|   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- avg_u_mbps >  8.07\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- avg_lat_ms >  308.17\n",
      "|   |   |   |   |--- percent_usuf <= 0.37\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- percent_usuf >  0.37\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|--- avg_lat_ms >  355.00\n",
      "|   |--- avg_u_mbps <= 9.12\n",
      "|   |   |--- value: [2.00]\n",
      "|   |--- avg_u_mbps >  9.12\n",
      "|   |   |--- avg_lat_ms <= 443.58\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- avg_lat_ms >  443.58\n",
      "|   |   |   |--- value: [2.00]\n",
      "\n",
      "Desion Tree Mean Squared Error (MSE): 0.04\n",
      "Desion Tree Root Mean Squared Error (RMSE): 0.2\n",
      "Desion Tree Mean Absolute Error (MAE): 0.04\n",
      "Desion Tree R² Score: 0.904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        50\n",
      "           1       0.94      0.98      0.96        62\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           0.96       125\n",
      "   macro avg       0.97      0.97      0.97       125\n",
      "weighted avg       0.96      0.96      0.96       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "tree_rules = export_text(tree_model, feature_names=list(X.columns))\n",
    "print(tree_rules)\n",
    "# Mean Squared Error\n",
    "tree_model_mse = round(metrics.mean_squared_error(y_test, tree_model_y_pred),3)\n",
    "print(f\"Desion Tree Mean Squared Error (MSE): {tree_model_mse}\")\n",
    "\n",
    "# Root Mean Squared Error\n",
    "tree_model_rmse = round(np.sqrt(tree_model_mse),3)\n",
    "print(f\"Desion Tree Root Mean Squared Error (RMSE): {tree_model_rmse}\")\n",
    "\n",
    "# Mean Absolute Error\n",
    "tree_model_mae = round(metrics.mean_absolute_error(y_test, tree_model_y_pred),3)\n",
    "print(f\"Desion Tree Mean Absolute Error (MAE): {tree_model_mae}\")\n",
    "\n",
    "# R² Score\n",
    "tree_model_r2 = round(metrics.r2_score(y_test, tree_model_y_pred),3)\n",
    "print(f\"Desion Tree R² Score: {tree_model_r2}\")\n",
    "print(classification_report(y_test, tree_model_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5547c722",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28cb01",
   "metadata": {},
   "source": [
    "### SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa5c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVM classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "svm_y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab5c3a",
   "metadata": {},
   "source": [
    "### SVM Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe30b5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 1.0\n",
      "SVM Mean Squared Error (MSE): 0.0\n",
      "SVM Root Mean Squared Error (RMSE): 0.0\n",
      "SVM Mean Absolute Error (MAE): 0.0\n",
      "SVM R² Score: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00        62\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00       125\n",
      "   macro avg       1.00      1.00      1.00       125\n",
      "weighted avg       1.00      1.00      1.00       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_y_pred))\n",
    "\n",
    "# Mean Squared Error\n",
    "svm_mse = round(metrics.mean_squared_error(y_test, svm_y_pred),3)\n",
    "print(f\"SVM Mean Squared Error (MSE): {svm_mse}\")\n",
    "\n",
    "# Root Mean Squared Error\n",
    "svm_rmse = round(np.sqrt(svm_mse),3)\n",
    "print(f\"SVM Root Mean Squared Error (RMSE): {svm_rmse}\")\n",
    "\n",
    "# Mean Absolute Error\n",
    "svm_mae = round(metrics.mean_absolute_error(y_test, svm_y_pred),3)\n",
    "print(f\"SVM Mean Absolute Error (MAE): {svm_mae}\")\n",
    "\n",
    "# R² Score\n",
    "svm_r2 = round(metrics.r2_score(y_test, svm_y_pred),3)\n",
    "print(f\"SVM R² Score: {svm_r2}\")\n",
    "\n",
    "# Model Evaluation: precision, recall, f1-score, support\n",
    "print(classification_report(y_test, svm_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979cf0c-04ec-4ef8-b9c5-f3ca7b9616f6",
   "metadata": {},
   "source": [
    "## Comparison of Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b714e-54a8-41e2-9638-6dd5cf0369ab",
   "metadata": {},
   "source": [
    "Compare the statistics we drew from the last section to see if the key features (those with the greatest weights) matches up with our unsupervised learning results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403386ca-8038-4c6b-924d-0e7ef068700c",
   "metadata": {},
   "source": [
    "### R squared analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac81eea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso R² Score: 0.676\n",
      "Linear Regression R² Score: 0.678\n",
      "Desion Tree R² Score: 0.904\n",
      "SVM Mean Squared Error (MSE): **1.000**\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression R² Score\n",
    "print(f\"Lasso R² Score: {lasso_r2}\")\n",
    "\n",
    "# Linear Regression R² Score\n",
    "print(f\"Linear Regression R² Score: {linear_regr_r2}\")\n",
    "\n",
    "# Decision Tree R² Score\n",
    "print(f\"Desion Tree R² Score: {tree_model_r2}\")\n",
    "\n",
    "# SVM R² Score\n",
    "print(\"SVM Mean Squared Error (MSE): **{:.3f}**\".format(svm_r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec8a91-7482-42e5-829a-ae4161ad7566",
   "metadata": {},
   "source": [
    "From this we can see that the SVM is superior to that of the the tree regressor. The r^2 value is higher so we can deduce that the SVM model is a better fit for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6a318-093d-4849-8484-a3d7c0a30783",
   "metadata": {},
   "source": [
    "### MSE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223e386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Mean Squared Error (MSE): 0.135\n",
      "Linear Regression Mean Squared Error (MSE): 0.134\n",
      "Desion Tree Mean Squared Error (MSE): 0.04\n",
      "SVM Mean Squared Error (MSE): **0.000**\n"
     ]
    }
   ],
   "source": [
    "# Print Lasso Mean Squared Error\n",
    "print(f\"Lasso Mean Squared Error (MSE): {lasso_mse}\")\n",
    "\n",
    "# Mean Squared Error\n",
    "print(f\"Linear Regression Mean Squared Error (MSE): {linear_regr_mse}\")\n",
    "\n",
    "# Mean Squared Error\n",
    "print(f\"Desion Tree Mean Squared Error (MSE): {tree_model_mse}\")\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"SVM Mean Squared Error (MSE): **{:.3f}**\".format(svm_mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0385e-ce44-4e6e-8fb6-f835fc28138d",
   "metadata": {},
   "source": [
    "The **MSE is lowest in our SVM model** so we can deduce that overall, the SVM model is a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95bcf26-40c1-49d4-a790-6995e3c597dc",
   "metadata": {},
   "source": [
    "## Policy Recommendation\n",
    "Using the weights of the features of the SVM model, we can deduce which features are more significant in predicting digital equity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae52d033-145a-4ce7-b292-f42248b26adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature at Index 0 Name: bslcount\n",
      "Feature at Index 1 Name: usufcount\n",
      "Feature at Index 2 Name: percent_usuf\n",
      "Feature at Index 3 Name: avg_d_mbps\n",
      "Feature at Index 4 Name: avg_u_mbps\n",
      "Feature at Index 5 Name: avg_lat_ms\n",
      "\n",
      "Cluster: 0 Good Network\n",
      "Feature with highest absolute weight: avg_u_mbps\n",
      "Highest absolute weight: -1.768716954472417\n",
      "Feature with lowest absolute weight: usufcount\n",
      "Lowest absolute weight: 0.0011145075586185271\n",
      "\n",
      "Cluster: 1 Excellent Network\n",
      "Feature with highest absolute weight: avg_lat_ms\n",
      "Highest absolute weight: -0.09679614294400896\n",
      "Feature with lowest absolute weight: percent_usuf\n",
      "Lowest absolute weight: 0.0039606674403634065\n",
      "\n",
      "Cluster: 2 Poor or no Network\n",
      "Feature with highest absolute weight: avg_d_mbps\n",
      "Highest absolute weight: 0.09540398255401014\n",
      "Feature with lowest absolute weight: percent_usuf\n",
      "Lowest absolute weight: 0.0002972824275481404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = clf.coef_\n",
    "feature_names = clf.feature_names_in_\n",
    "\n",
    "cluster_names = ['Good Network', 'Excellent Network', 'Poor or no Network']\n",
    "\n",
    "for index, value in enumerate(feature_names):\n",
    "    print(\"Feature at Index\", index, \"Name:\", value)\n",
    "print()\n",
    "\n",
    "# Print which feature had the highest and lowest relevant factors\n",
    "for i in range(clf.coef_.shape[0]):\n",
    "    weights = clf.coef_[i]\n",
    "    index_of_highest_weight = np.argmax(np.abs(weights))\n",
    "    index_of_lowest_weight = np.argmin(np.abs(weights))\n",
    "    print(\"Cluster:\", i, cluster_names[i])\n",
    "    print(\"Feature with highest absolute weight:\", feature_names[index_of_highest_weight])\n",
    "\n",
    "\n",
    "    print(\"Highest absolute weight:\", weights[index_of_highest_weight])\n",
    "    print(\"Feature with lowest absolute weight:\", feature_names[index_of_lowest_weight])\n",
    "\n",
    "    print(\"Lowest absolute weight:\", weights[index_of_lowest_weight])\n",
    "\n",
    "                                            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf40b0-0b89-41c4-9702-cde217f7a45e",
   "metadata": {},
   "source": [
    "### Interpretation of Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c7513-4af6-4bc1-b440-bf9945b0aa55",
   "metadata": {},
   "source": [
    "We find that the download speed has a high correlation to all of the other metrics, so we can deduce that download speed is the main indicator of digital equity, something that is confirmed from our unsupervised learning models.\n",
    "\n",
    "Using the coef_ method to return the weights of the svm model tells us the coefficients of each feature in the linear equation that defines the decision boundary between the classes. The higher the absolute value of the weight, the more important the feature is for the classification. For example, in this case, the feature with the highest weight for cluster 2 is **avg_d_mbps**, which means that the average download speed is the most influential factor in determining if the cluster label for a section should be 2. The feature with the lowest weight for cluster 2 is **percent_usuf**, which means that the percentage of unserverved and or unfunded households in a section is the least relevant factor for cluster 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a08a63b-0bbf-4e2e-86ce-11ba7b5fa1ff",
   "metadata": {},
   "source": [
    "### Our Policy Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a090c9-181f-4677-a198-4c6dc6b6c45c",
   "metadata": {},
   "source": [
    "Thus, we recommend that the FCC use low download speed as the primary indicator of a lack of high speed internet access, since all the other features we looked at correlate highly with download speed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
